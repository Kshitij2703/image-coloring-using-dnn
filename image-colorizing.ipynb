{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9787632,"sourceType":"datasetVersion","datasetId":5997041},{"sourceId":9787693,"sourceType":"datasetVersion","datasetId":5997089}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:49:03.765740Z","iopub.execute_input":"2024-11-02T13:49:03.766394Z","iopub.status.idle":"2024-11-02T13:49:03.775855Z","shell.execute_reply.started":"2024-11-02T13:49:03.766347Z","shell.execute_reply":"2024-11-02T13:49:03.774971Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"Using GPUs:\", gpus)\n    except RuntimeError as e:\n        print(\"Error initializing GPUs:\", e)\nelse:\n    print(\"No GPUs available.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:49:05.583972Z","iopub.execute_input":"2024-11-02T13:49:05.584695Z","iopub.status.idle":"2024-11-02T13:49:19.807749Z","shell.execute_reply.started":"2024-11-02T13:49:05.584656Z","shell.execute_reply":"2024-11-02T13:49:19.806888Z"}},"outputs":[{"name":"stdout","text":"Using GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"for gpu in tf.config.list_physical_devices('GPU'):\n    tf.config.experimental.set_memory_growth(gpu, True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:49:48.470544Z","iopub.execute_input":"2024-11-02T13:49:48.470938Z","iopub.status.idle":"2024-11-02T13:49:48.475680Z","shell.execute_reply.started":"2024-11-02T13:49:48.470888Z","shell.execute_reply":"2024-11-02T13:49:48.474697Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport numpy as np\nimport os\nfrom PIL import Image\nimport cv2\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:49:50.490831Z","iopub.execute_input":"2024-11-02T13:49:50.491376Z","iopub.status.idle":"2024-11-02T13:49:51.282318Z","shell.execute_reply.started":"2024-11-02T13:49:50.491313Z","shell.execute_reply":"2024-11-02T13:49:51.281320Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def build_colorization_model(input_shape=(256, 256, 1)):\n    inputs = Input(shape=input_shape)\n    x = Lambda(lambda x: x * 2 - 1)(inputs)\n    \n    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    block1 = x\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    block2 = x\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(256, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    block3 = x\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(512, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(512, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    \n    x = UpSampling2D()(x)\n    x = Concatenate()([x, block3])\n    x = Conv2D(256, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    \n    x = UpSampling2D()(x)\n    x = Concatenate()([x, block2])\n    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    \n    x = UpSampling2D()(x)\n    x = Concatenate()([x, block1])\n    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    \n    outputs = Conv2D(2, 1, padding='same', activation='sigmoid')(x)\n    outputs = Lambda(lambda x: x * 2 - 1)(outputs)\n    \n    return Model(inputs=inputs, outputs=outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:50:01.639838Z","iopub.execute_input":"2024-11-02T13:50:01.640722Z","iopub.status.idle":"2024-11-02T13:50:01.656229Z","shell.execute_reply.started":"2024-11-02T13:50:01.640678Z","shell.execute_reply":"2024-11-02T13:50:01.655161Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    if img is None:\n        raise ValueError(f\"Could not read image at {image_path}\")\n    img = cv2.resize(img, (256, 256))\n    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    l_channel = lab_img[:, :, 0] / 255.0\n    return np.expand_dims(l_channel, axis=[0, -1])\n\ndef postprocess_lab_to_rgb(L, ab_channels):\n    L = L[0, :, :, 0] * 255.0\n    a = (ab_channels[0, :, :, 0] + 1) * 127.5\n    b = (ab_channels[0, :, :, 1] + 1) * 127.5\n    lab_image = np.stack([L, a, b], axis=-1).astype(np.float32)\n    rgb_image = cv2.cvtColor(lab_image.astype(np.float32), cv2.COLOR_LAB2RGB)\n    rgb_image = cv2.convertScaleAbs(rgb_image, alpha=1.2, beta=5)\n    hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV).astype(np.float32)\n    hsv_image[:, :, 1] = hsv_image[:, :, 1] * 1.4\n    hsv_image = np.clip(hsv_image, 0, 255).astype(np.uint8)\n    rgb_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n    return rgb_image\n\ndef custom_loss():\n    def loss(y_true, y_pred):\n        mse = tf.reduce_mean(tf.square(y_true - y_pred))\n        tv_loss = tf.reduce_mean(tf.image.total_variation(y_pred))\n        return mse + 0.001 * tv_loss\n    return loss\n\ndef load_and_preprocess_data(data_dir):\n    image_files = [f for f in os.listdir(data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    X = []\n    Y = []\n    \n    for img_file in image_files:\n        img_path = os.path.join(data_dir, img_file)\n        img = cv2.imread(img_path)\n        if img is not None:\n            img = cv2.resize(img, (256, 256))\n            lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n            \n            l_channel = lab_img[:, :, 0]\n            ab_channels = lab_img[:, :, 1:]\n            \n            X.append(l_channel.reshape(256, 256, 1))\n            Y.append(ab_channels)\n    \n    return np.array(X) / 255.0, (np.array(Y) - 128) / 127.0\n\ndef prepare_dataset(data_dir):\n    X, Y = load_and_preprocess_data(data_dir)\n    \n    X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, train_size=0.7, random_state=42)\n    X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n    \n    return (X_train, Y_train), (X_val, Y_val), (X_test, Y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:50:15.531340Z","iopub.execute_input":"2024-11-02T13:50:15.531733Z","iopub.status.idle":"2024-11-02T13:50:15.548380Z","shell.execute_reply.started":"2024-11-02T13:50:15.531696Z","shell.execute_reply":"2024-11-02T13:50:15.546992Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train_model(data_dir, output_dir, batch_size=32, epochs=20):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    (X_train, Y_train), (X_val, Y_val), (X_test, Y_test) = prepare_dataset(data_dir)\n    \n    model = build_colorization_model()\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                 loss=custom_loss(),\n                 metrics=['mae'])\n    \n    callbacks = [\n        ModelCheckpoint(os.path.join(output_dir, 'best_model.keras'), \n                       save_best_only=True, \n                       monitor='val_loss'),\n        EarlyStopping(patience=10, restore_best_weights=True),\n        ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)\n    ]\n    \n    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True\n    )\n    \n    history = model.fit(\n        datagen.flow(X_train, Y_train, batch_size=batch_size),\n        validation_data=(X_val, Y_val),\n        epochs=epochs,\n        callbacks=callbacks\n    )\n    \n    model.save(os.path.join(output_dir, 'final_model.keras'))\n    test_loss = model.evaluate(X_test, Y_test)\n    print(f'Test Loss: {test_loss[0]:.4f}')\n    print(f'Test MAE: {test_loss[1]:.4f}')\n    \n    return model, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:51:10.961024Z","iopub.execute_input":"2024-11-02T13:51:10.961901Z","iopub.status.idle":"2024-11-02T13:51:10.971972Z","shell.execute_reply.started":"2024-11-02T13:51:10.961860Z","shell.execute_reply":"2024-11-02T13:51:10.971049Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    DATA_DIR = \"/kaggle/input/old-images\"\n    OUTPUT_DIR = \"/kaggle/working/\"\n    \n    model, history = train_model(DATA_DIR, OUTPUT_DIR)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T13:53:07.114845Z","iopub.execute_input":"2024-11-02T13:53:07.115759Z","iopub.status.idle":"2024-11-02T14:07:15.773046Z","shell.execute_reply.started":"2024-11-02T13:53:07.115715Z","shell.execute_reply":"2024-11-02T14:07:15.772124Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730555628.956573     126 service.cc:145] XLA service 0x7f2c1040c6f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730555628.956644     126 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730555628.956648     126 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n2024-11-02 13:53:59.195770: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng12{k11=2} for conv (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-02 13:53:59.376558: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.180899052s\nTrying algorithm eng12{k11=2} for conv (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-02 13:55:27.810257: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=2,k3=0} for conv (f32[64,192,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,192,256,256]{3,2,1,0}, f32[32,64,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-02 13:55:27.975867: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.165791304s\nTrying algorithm eng20{k2=2,k3=0} for conv (f32[64,192,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,192,256,256]{3,2,1,0}, f32[32,64,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-02 13:55:28.976138: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[64,192,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,192,256,256]{3,2,1,0}, f32[32,64,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-11-02 13:55:29.201401: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.225441112s\nTrying algorithm eng1{k2=2,k3=0} for conv (f32[64,192,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,192,256,256]{3,2,1,0}, f32[32,64,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\nI0000 00:00:1730555733.135624     126 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4s/step - loss: 18.8726 - mae: 0.8023 - val_loss: 3.3210 - val_mae: 0.9757 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 3.1433 - mae: 0.8348 - val_loss: 4.4805 - val_mae: 0.9316 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - loss: 2.3926 - mae: 0.7574 - val_loss: 3.2632 - val_mae: 0.8050 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 1.9298 - mae: 0.6381 - val_loss: 1.0431 - val_mae: 0.5454 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 1.1672 - mae: 0.4319 - val_loss: 1.0513 - val_mae: 0.4359 - learning_rate: 0.0010\nEpoch 6/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.7743 - mae: 0.2823 - val_loss: 0.6600 - val_mae: 0.3126 - learning_rate: 0.0010\nEpoch 7/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.6252 - mae: 0.2007 - val_loss: 1.5874 - val_mae: 0.2970 - learning_rate: 0.0010\nEpoch 8/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.5414 - mae: 0.1439 - val_loss: 2.0162 - val_mae: 0.6266 - learning_rate: 0.0010\nEpoch 9/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.5565 - mae: 0.1425 - val_loss: 0.3259 - val_mae: 0.0969 - learning_rate: 0.0010\nEpoch 10/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.4839 - mae: 0.1722 - val_loss: 0.4117 - val_mae: 0.1406 - learning_rate: 0.0010\nEpoch 11/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.4553 - mae: 0.2024 - val_loss: 1.3836 - val_mae: 0.2995 - learning_rate: 0.0010\nEpoch 12/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.3451 - mae: 0.2429 - val_loss: 0.2152 - val_mae: 0.1809 - learning_rate: 0.0010\nEpoch 13/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.3740 - mae: 0.2419 - val_loss: 0.2416 - val_mae: 0.1810 - learning_rate: 0.0010\nEpoch 14/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 0.3891 - mae: 0.2444 - val_loss: 0.5654 - val_mae: 0.2056 - learning_rate: 0.0010\nEpoch 15/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 0.3054 - mae: 0.2403 - val_loss: 0.3770 - val_mae: 0.1967 - learning_rate: 0.0010\nEpoch 16/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.3048 - mae: 0.2459 - val_loss: 0.1987 - val_mae: 0.1923 - learning_rate: 0.0010\nEpoch 17/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.2360 - mae: 0.2299 - val_loss: 0.1720 - val_mae: 0.1809 - learning_rate: 0.0010\nEpoch 18/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 0.2490 - mae: 0.2282 - val_loss: 0.1884 - val_mae: 0.1828 - learning_rate: 0.0010\nEpoch 19/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 0.2450 - mae: 0.2075 - val_loss: 0.1512 - val_mae: 0.1745 - learning_rate: 0.0010\nEpoch 20/20\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 0.3185 - mae: 0.2020 - val_loss: 0.4979 - val_mae: 0.1876 - learning_rate: 0.0010\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 284ms/step - loss: 0.1910 - mae: 0.1933\nTest Loss: 0.1798\nTest MAE: 0.1880\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport os\nfrom tensorflow.keras.models import load_model\n\n@tf.keras.utils.register_keras_serializable(name='CustomColorLoss')\nclass CustomColorLoss(tf.keras.losses.Loss):\n    def __init__(self, name='custom_color_loss', **kwargs):\n        super().__init__(name=name, **kwargs)\n        \n    def call(self, y_true, y_pred):\n        mse = tf.reduce_mean(tf.square(y_true - y_pred))\n        # Add total variation for smoothness\n        tv_loss = tf.reduce_mean(tf.image.total_variation(y_pred))\n        return mse + 0.001 * tv_loss\n\ndef preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    print(f\"Original image shape: {img.shape}\")\n    \n    img = cv2.resize(img, (256, 256))\n    print(f\"Resized image shape: {img.shape}\")\n    \n    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    \n    l_channel = lab_img[:, :, 0].astype(np.float32) / 255.0\n    \n    print(f\"L channel stats - min: {l_channel.min():.3f}, max: {l_channel.max():.3f}\")\n    return np.expand_dims(l_channel, axis=[0, -1])\n\ndef postprocess_lab_to_rgb(L, ab_channels):\n    print(f\"Input L range: [{L.min():.3f}, {L.max():.3f}]\")\n    print(f\"Input ab range: [{ab_channels.min():.3f}, {ab_channels.max():.3f}]\")\n    \n    L = L[0, :, :, 0] * 100.0\n    \n    a = ab_channels[0, :, :, 0] * 128.0\n    b = ab_channels[0, :, :, 1] * 128.0\n    \n    lab_image = np.stack([L, a, b], axis=-1).astype(np.float32)\n    \n    lab_image[:, :, 0] = np.clip(lab_image[:, :, 0], 0, 100)\n    lab_image[:, :, 1:] = np.clip(lab_image[:, :, 1:], -128, 127)\n    \n    print(\"LAB ranges after scaling:\")\n    print(f\"L: [{lab_image[:,:,0].min():.1f}, {lab_image[:,:,0].max():.1f}]\")\n    print(f\"a: [{lab_image[:,:,1].min():.1f}, {lab_image[:,:,1].max():.1f}]\")\n    print(f\"b: [{lab_image[:,:,2].min():.1f}, {lab_image[:,:,2].max():.1f}]\")\n    \n    rgb_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2RGB)\n    \n    rgb_image = np.clip(rgb_image * 255.0, 0, 255).astype(np.uint8)\n    \n    rgb_image = cv2.convertScaleAbs(rgb_image, alpha=1.1, beta=5)\n    \n    hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV).astype(np.float32)\n    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * 1.2, 0, 255)\n    hsv_image = hsv_image.astype(np.uint8)\n    rgb_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n    \n    return rgb_image\n\ntest_image_path = \"/kaggle/input/old-images/1054.jpg\"\noutput_image_path = \"/kaggle/working/colored_1054.jpg\"\nmodel_path = os.path.join(OUTPUT_DIR, 'best_model.keras')\n\nprint(\"Loading model...\")\ntry:\n    model = load_model(model_path, \n                      custom_objects={'CustomColorLoss': CustomColorLoss,\n                                    'custom_color_loss': CustomColorLoss()})\n    print(\"Model loaded successfully\")\nexcept Exception as e:\n    print(f\"Error loading model: {str(e)}\")\n    raise\n\nprint(\"\\nProcessing image...\")\nimg_array = preprocess_image(test_image_path)\nprint(f\"Input array shape: {img_array.shape}\")\n\nprint(\"\\nGenerating color predictions...\")\nab_channels = model.predict(img_array)\nprint(f\"Predictions shape: {ab_channels.shape}\")\nprint(f\"Predictions range: [{ab_channels.min():.3f}, {ab_channels.max():.3f}]\")\n\nprint(\"\\nConverting to RGB...\")\nrgb_image = postprocess_lab_to_rgb(img_array, ab_channels)\nprint(f\"Final RGB shape: {rgb_image.shape}\")\nprint(f\"Final RGB range: [{rgb_image.min()}, {rgb_image.max()}]\")\n\nImage.fromarray(rgb_image).save(output_image_path)\nprint(\"\\nImage saved successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T14:30:11.137140Z","iopub.execute_input":"2024-11-02T14:30:11.137605Z","iopub.status.idle":"2024-11-02T14:30:14.161883Z","shell.execute_reply.started":"2024-11-02T14:30:11.137559Z","shell.execute_reply":"2024-11-02T14:30:14.160983Z"}},"outputs":[{"name":"stdout","text":"Loading model...\nModel loaded successfully\n\nProcessing image...\nOriginal image shape: (373, 600, 3)\nResized image shape: (256, 256, 3)\nL channel stats - min: 0.004, max: 1.000\nInput array shape: (1, 256, 256, 1)\n\nGenerating color predictions...\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917ms/step\nPredictions shape: (1, 256, 256, 2)\nPredictions range: [0.051, 0.179]\n\nConverting to RGB...\nInput L range: [0.004, 1.000]\nInput ab range: [0.051, 0.179]\nLAB ranges after scaling:\nL: [0.4, 100.0]\na: [21.8, 22.9]\nb: [6.6, 8.0]\nFinal RGB shape: (256, 256, 3)\nFinal RGB range: [0, 255]\n\nImage saved successfully\n","output_type":"stream"}],"execution_count":35}]}